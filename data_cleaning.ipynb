{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Cleaning\"\n",
    "format: html\n",
    "execute:\n",
    "    echo: true\n",
    "link-external-newwindow: true\n",
    "bibliography: reference.bib\n",
    "website:\n",
    "  back-to-top-navigation: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In the world of data science, 'Data Cleaning' is the unsung hero of the data journey. It's the process where the raw data, often messy and imperfect, transforms into a reliable and trustworthy foundation for analysis. Data cleaning involves identifying and rectifying inconsistencies, errors, and missing values within datasets. Without this critical step, the insights drawn from data can be inaccurate, leading to misguided decisions. I understand the significance of data cleaning in ensuring the integrity and reliability of datasets, and I apply meticulous attention to detail to uncover hidden patterns and meaningful insights buried within the data. I will walk through the pre-processing steps I took for the data mentioned in the [Data Gathering](https://patricia-schenfeld.georgetown.domains/dsan-website/5000-website/_site/data_gathering.html) tab. \n",
    "\n",
    "## News API\n",
    "\n",
    "### Raw Data\n",
    "I requested data from the News API using Python to request English articles that relate to Spotify. The response data was collected to a JSON file for further analysis and processing. Below is a screenshot of what the raw data looks like. You can see it contains each article along with its attributes such as author, title, description, etc. For access to the raw data, click [here.](https://github.com/anly501/dsan-5000-project-pschenfeld/blob/main/data/raw_data/news_api/2023-09-28-H18-M42-S20-newapi-raw-data.json)\n",
    "\n",
    "![](images/news_api_raw.png)\n",
    "\n",
    "### Cleaning the Data\n",
    "I defined a function, 'string_cleaner' that takes an input string, applies a series of cleaning operations to remove unwanted characters, punctuation, and extra spaces, and then converts the text to lowercase. This function is useful for preparing text data for analysis or natural language processing tasks by ensuring that the text is standardized and cleaned of noise. Below is a screenshot of what the Spotify article text looks like after cleaning. For access to the clean data file, click [here.](https://github.com/anly501/dsan-5000-project-pschenfeld/blob/main/data/clean_data/news_api/news_api_clean.csv)\n",
    "\n",
    "![](images/spotify_news_api_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electronic Dance Music Subgenres\n",
    "\n",
    "### Raw Data\n",
    "Each genre has a separate table containing 10 of the most popular DJs for that genre, along with those artists' audio features. These features include danceability, energy, key, loudness, etc. I used the Spotify API in R in order to create this dataset. For access to the raw data files, click [here](https://github.com/anly501/dsan-5000-project-pschenfeld/tree/main/data/raw_data/edm_subgenres).\n",
    "\n",
    "![](images/tech_house_raw.png)\n",
    "\n",
    "### Cleaning the Data\n",
    "I performed the same cleaning steps across all 5 subgenre datasets. I first took note of the shape of each dataset, which can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4367, 15)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trance = pd.read_csv('../../data/raw_data/edm_subgenres/trance_audio_features.csv')\n",
    "techno = pd.read_csv('../../data/raw_data/edm_subgenres/techno_audio_features_raw.csv')\n",
    "tech_house = pd.read_csv('../../data/raw_data/edm_subgenres/tech_house_audio_features_raw.csv')\n",
    "dnb = pd.read_csv('../../data/raw_data/edm_subgenres/dnb_audio_features_raw.csv')\n",
    "dubstep = pd.read_csv('../../data/raw_data/edm_subgenres/dubstep_audio_features_raw.csv')\n",
    "\n",
    "trance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4234, 14)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4362, 14)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_house.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3858, 14)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3790, 14)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dubstep.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Luckily, for all of the datasets, the datatypes were proper and the column names were sufficient. There were no missing values in trance, techno, tech_house, or dnb datasets. However, in the dubstep dataframe, there were a handful of missing values which I needed to further investigate. After looking at the total null values for each column, I then filtered the dataframe to show only rows with null values, this way I coud get a sense of what was missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name         0\n",
       "danceability        4\n",
       "energy              4\n",
       "key                 4\n",
       "loudness            4\n",
       "mode                4\n",
       "speechiness         4\n",
       "acousticness        4\n",
       "instrumentalness    4\n",
       "liveness            4\n",
       "valence             4\n",
       "tempo               4\n",
       "duration_ms         4\n",
       "time_signature      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dubstep.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Excision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Excision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Excision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_name  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "10    Excision           NaN     NaN  NaN       NaN   NaN          NaN   \n",
       "16    Excision           NaN     NaN  NaN       NaN   NaN          NaN   \n",
       "36    Excision           NaN     NaN  NaN       NaN   NaN          NaN   \n",
       "46    Excision           NaN     NaN  NaN       NaN   NaN          NaN   \n",
       "\n",
       "    acousticness  instrumentalness  liveness  valence  tempo  duration_ms  \\\n",
       "10           NaN               NaN       NaN      NaN    NaN          NaN   \n",
       "16           NaN               NaN       NaN      NaN    NaN          NaN   \n",
       "36           NaN               NaN       NaN      NaN    NaN          NaN   \n",
       "46           NaN               NaN       NaN      NaN    NaN          NaN   \n",
       "\n",
       "    time_signature  \n",
       "10             NaN  \n",
       "16             NaN  \n",
       "36             NaN  \n",
       "46             NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the missing values in the dataaet\n",
    "null_data = dubstep[dubstep.isnull().any(axis=1)]\n",
    "null_data\n",
    "\n",
    "# It appears all missing values are only for the artist Excision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I noticed that there were 4 rows in total that have complete null values for all columns (besides artist name). All 4 rows are for the artist Excision, so I further wanted to look at how many records there are for Excision as a whole, before I decided what to do with the missing values. I filtered the dataset to show only records for the artist Excision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.875</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.171</td>\n",
       "      <td>149.960</td>\n",
       "      <td>196233.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.981</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6060</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.06590</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.139</td>\n",
       "      <td>149.723</td>\n",
       "      <td>243200.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.967</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.82100</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.148</td>\n",
       "      <td>149.776</td>\n",
       "      <td>203224.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.976</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.24100</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.174</td>\n",
       "      <td>74.415</td>\n",
       "      <td>189342.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.280</td>\n",
       "      <td>75.373</td>\n",
       "      <td>228800.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.438</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-7.420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.40900</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.545</td>\n",
       "      <td>139.959</td>\n",
       "      <td>308529.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.958</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.81200</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.364</td>\n",
       "      <td>144.003</td>\n",
       "      <td>279200.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.93900</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.714</td>\n",
       "      <td>139.997</td>\n",
       "      <td>344666.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.770</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.90800</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.435</td>\n",
       "      <td>139.866</td>\n",
       "      <td>287997.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Excision</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.840</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.68900</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.293</td>\n",
       "      <td>134.455</td>\n",
       "      <td>399488.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist_name  danceability  energy   key  loudness  mode  speechiness  \\\n",
       "0      Excision         0.379   0.875   7.0    -2.201   0.0       0.0648   \n",
       "1      Excision         0.576   0.981  10.0     0.381   0.0       0.6060   \n",
       "2      Excision         0.295   0.967   2.0    -2.940   1.0       0.1740   \n",
       "3      Excision         0.368   0.976   8.0    -0.904   1.0       0.1750   \n",
       "4      Excision         0.319   0.983   1.0    -0.480   1.0       0.3800   \n",
       "..          ...           ...     ...   ...       ...   ...          ...   \n",
       "112    Excision         0.875   0.438  11.0    -7.420   1.0       0.0769   \n",
       "113    Excision         0.781   0.958  11.0    -9.255   0.0       0.0996   \n",
       "114    Excision         0.763   0.987   0.0   -10.080   1.0       0.0607   \n",
       "115    Excision         0.577   0.770   2.0    -7.818   1.0       0.0760   \n",
       "116    Excision         0.534   0.840   7.0    -9.990   1.0       0.3440   \n",
       "\n",
       "     acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0        0.006250           0.00000     0.182    0.171  149.960     196233.0   \n",
       "1        0.007790           0.06590     0.197    0.139  149.723     243200.0   \n",
       "2        0.000213           0.82100     0.705    0.148  149.776     203224.0   \n",
       "3        0.004530           0.24100     0.141    0.174   74.415     189342.0   \n",
       "4        0.007900           0.00144     0.100    0.280   75.373     228800.0   \n",
       "..            ...               ...       ...      ...      ...          ...   \n",
       "112      0.000553           0.40900     0.102    0.545  139.959     308529.0   \n",
       "113      0.003450           0.81200     0.219    0.364  144.003     279200.0   \n",
       "114      0.001350           0.93900     0.187    0.714  139.997     344666.0   \n",
       "115      0.063000           0.90800     0.364    0.435  139.866     287997.0   \n",
       "116      0.004740           0.68900     0.182    0.293  134.455     399488.0   \n",
       "\n",
       "     time_signature  \n",
       "0               4.0  \n",
       "1               4.0  \n",
       "2               4.0  \n",
       "3               4.0  \n",
       "4               4.0  \n",
       "..              ...  \n",
       "112             4.0  \n",
       "113             4.0  \n",
       "114             4.0  \n",
       "115             4.0  \n",
       "116             4.0  \n",
       "\n",
       "[117 rows x 14 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at all rows for Excision\n",
    "dubstep.loc[dubstep['artist_name'] == 'Excision']\n",
    "\n",
    "# We have 116 rows for Excision, and 4 of those rows have all missing values. If we drop these 4 rows that would be 3.45% of Excision data, but only \n",
    "# .32% of the entire dataset. In this case, we can drop the rows as it does not pose the threat of losing a lot of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Based off of the output, there were 116 records for Excision, so if I decided to drop these 4 rows that would mean losing 3.45% of Excision data, or .32% of the total dataset. Based off of these numbers, I decided it was safe to drop these rows. The final shape of the dataset is shown below (1245 rows & 14 columns to begin, 1241 rows & 14 columns to end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3786, 14)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dubstep = dubstep.dropna()\n",
    "dubstep.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then combined all the genre datasets into one large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For all clean subgenre data files, click [here](https://github.com/anly501/dsan-5000-project-pschenfeld/tree/main/data/clean_data/edm_subgenres)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify Revenue, Expenses, & Premium Users\n",
    "\n",
    "### Raw Data\n",
    "This dataset was taken from [Kaggle](https://www.kaggle.com/datasets/mauryansshivam/spotify-revenue-expenses-and-its-premium-users/data) and contains data pertaining to each quarter of the year with total revenue, cost of revenue, premium revenue and more. Below is a screenshot of what the raw data looks like. Click [here](https://github.com/anly501/dsan-5000-project-pschenfeld/blob/main/data/raw_data/revenue_expenses_premium_users/spotify_quarterly.csv) for the raw data file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cleaning the Data\n",
    "After loading the csv file into Python, I checked the shape of the initial raw data, which was 26 rows and 17 columns. I then began by taking a look at the top (head) and bottom (tail) of the data. When looking at the bottom, I noticed that the last row had all missing (NaN) values except for one column. I kept this in mind for later when dealing with missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 17)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/raw_data/revenue_expenses_premium_users/spotify_quarterly.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>Premium Revenue</th>\n",
       "      <th>Premium Cost Revenue</th>\n",
       "      <th>Premium Gross Profit</th>\n",
       "      <th>Ad Revenue</th>\n",
       "      <th>Ad Cost of revenue</th>\n",
       "      <th>Ad gross Profit</th>\n",
       "      <th>MAUs</th>\n",
       "      <th>Premium MAUs</th>\n",
       "      <th>Ad MAUs</th>\n",
       "      <th>Premium ARPU</th>\n",
       "      <th>Sales and Marketing Cost</th>\n",
       "      <th>Research and Development Cost</th>\n",
       "      <th>Genreal and Adminstraive Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>31-12-2017</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>173.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30-09-2017</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.06</td>\n",
       "      <td>138.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30-06-2017</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>146.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31-03-2017</td>\n",
       "      <td>902.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.46</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Total Revenue  Cost of Revenue  Gross Profit  Premium Revenue  \\\n",
       "21  31-12-2017         1449.0            867.0         582.0           1018.0   \n",
       "22  30-09-2017         1032.0            802.0         230.0            923.0   \n",
       "23  30-06-2017         1007.0            775.0         232.0            904.0   \n",
       "24  31-03-2017          902.0            797.0         105.0            828.0   \n",
       "25  31-12-2016            NaN              NaN           NaN              NaN   \n",
       "\n",
       "    Premium Cost Revenue  Premium Gross Profit  Ad Revenue  \\\n",
       "21                 761.0                 257.0       130.0   \n",
       "22                 711.0                 212.0       109.0   \n",
       "23                 686.0                 218.0       103.0   \n",
       "24                 710.0                 118.0        74.0   \n",
       "25                   NaN                   NaN         NaN   \n",
       "\n",
       "    Ad Cost of revenue  Ad gross Profit   MAUs  Premium MAUs  Ad MAUs  \\\n",
       "21               106.0             24.0  160.0          71.0     93.0   \n",
       "22                91.0             18.0  150.0          62.0     91.0   \n",
       "23                89.0             14.0  138.0          59.0     83.0   \n",
       "24                87.0            -13.0  131.0          52.0     82.0   \n",
       "25                 NaN              NaN    NaN           NaN      NaN   \n",
       "\n",
       "    Premium ARPU  Sales and Marketing Cost  Research and Development Cost  \\\n",
       "21          5.24                     173.0                          123.0   \n",
       "22          5.06                     138.0                           98.0   \n",
       "23          5.53                     146.0                           95.0   \n",
       "24          5.46                     110.0                           80.0   \n",
       "25          6.00                       NaN                            NaN   \n",
       "\n",
       "    Genreal and Adminstraive Cost  \n",
       "21                           73.0  \n",
       "22                           67.0  \n",
       "23                           70.0  \n",
       "24                           54.0  \n",
       "25                            NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I wanted to clean up the column names, so I removed any spaces and replaced them with underscores as well as made all column names lowercase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'total_revenue', 'cost_of_revenue', 'gross_profit',\n",
       "       'premium_revenue', 'premium_cost_revenue', 'premium_gross_profit',\n",
       "       'ad_revenue', 'ad_cost_of_revenue', 'ad_gross_profit', 'maus',\n",
       "       'premium_maus', 'ad_maus', 'premium_arpu', 'sales_and_marketing_cost',\n",
       "       'research_and_development_cost', 'genreal_and_adminstraive_cost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's change the column names to have no spaces and all lowercase\n",
    "def add_underscores(df):\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    return df\n",
    "\n",
    "df = add_underscores(df)\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I renamed any column names that had spelling mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'total_revenue', 'cost_of_revenue', 'gross_profit',\n",
       "       'premium_revenue', 'premium_cost_revenue', 'premium_gross_profit',\n",
       "       'ad_revenue', 'ad_cost_of_revenue', 'ad_gross_profit', 'maus',\n",
       "       'premium_maus', 'ad_maus', 'premium_arpu', 'sales_and_marketing_cost',\n",
       "       'research_and_development_cost', 'general_and_administrative_cost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, lets fix any spelling mistakes in the column names\n",
    "df = df.rename(columns={'genreal_and_adminstraive_cost': 'general_and_administrative_cost'}) \n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I summed up all of the missing values in the dataset. I kept in mind from earlier that the bottom row of the dataset was missing all values except for one column. Looking at the sum of null values, I knew that this was the only row missing any values and therefore it could be removed from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                               0\n",
       "total_revenue                      1\n",
       "cost_of_revenue                    1\n",
       "gross_profit                       1\n",
       "premium_revenue                    1\n",
       "premium_cost_revenue               1\n",
       "premium_gross_profit               1\n",
       "ad_revenue                         1\n",
       "ad_cost_of_revenue                 1\n",
       "ad_gross_profit                    1\n",
       "maus                               1\n",
       "premium_maus                       1\n",
       "ad_maus                            1\n",
       "premium_arpu                       0\n",
       "sales_and_marketing_cost           1\n",
       "research_and_development_cost      1\n",
       "general_and_administrative_cost    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 17)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I saved the cleaned data to a csv, which you can find [here](https://github.com/anly501/dsan-5000-project-pschenfeld/blob/main/data/clean_data/revenue_costs_premium/revenue_costs_premium.csv)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify User Behavior\n",
    "\n",
    "### Raw Data\n",
    "This dataset encompasses a wide range of user information, including demographics like age and gender, as well as details related to Spotify usage, such as preferred listening devices and subscription plans. It also delves into user preferences, including favorite music genres and podcast habits, offering valuable insights into Spotify's user base and their behaviors. Below is a screenshot of the raw data. For access to the file, click [here](https://github.com/anly501/dsan-5000-project-pschenfeld/blob/main/data/raw_data/spotify_user_behavior/spotify_user_behavior.csv).\n",
    "\n",
    "![](images/spotify_user_behavior_raw.png)\n",
    "\n",
    "### Cleaning the Data\n",
    "After loading the csv file into Python, I checked the shape of the initial raw data, which was 520 rows and 20 columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 20)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/raw_data/spotify_user_behavior/spotify_user_behavior.csv', keep_default_na=False)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I then looked at the columns and made them all lowercase and fixed any spelling errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'spotify_usage_period', 'spotify_listening_device',\n",
       "       'spotify_subscription_plan', 'premium_sub_willingness',\n",
       "       'preferred_premium_plan', 'preferred_listening_content',\n",
       "       'fav_music_genre', 'music_time_slot', 'music_influential_mood',\n",
       "       'music_lis_frequency', 'music_expl_method', 'music_rec_rating',\n",
       "       'pod_lis_frequency', 'fav_pod_genre', 'preferred_pod_format',\n",
       "       'pod_host_preference', 'preferred_pod_duration',\n",
       "       'pod_variety_satisfaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df = df.rename(columns={'preffered_premium_plan': 'preferred_premium_plan', \n",
    "'music_influencial_mood': 'music_influential_mood', 'music_recc_rating': 'music_rec_rating', \n",
    "'preffered_pod_format': 'preferred_pod_format', 'preffered_pod_duration': 'preferred_pod_duration'})\n",
    "df.columns "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I finally checked the data types of the columns to make sure they were all the correct type, as well as checked for any missing values in the dataset. Luckily, no data types needed to be changed and there were no missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            object\n",
       "gender                         object\n",
       "spotify_usage_period           object\n",
       "spotify_listening_device       object\n",
       "spotify_subscription_plan      object\n",
       "premium_sub_willingness        object\n",
       "preferred_premium_plan         object\n",
       "preferred_listening_content    object\n",
       "fav_music_genre                object\n",
       "music_time_slot                object\n",
       "music_influential_mood         object\n",
       "music_lis_frequency            object\n",
       "music_expl_method              object\n",
       "music_rec_rating                int64\n",
       "pod_lis_frequency              object\n",
       "fav_pod_genre                  object\n",
       "preferred_pod_format           object\n",
       "pod_host_preference            object\n",
       "preferred_pod_duration         object\n",
       "pod_variety_satisfaction       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            0\n",
       "gender                         0\n",
       "spotify_usage_period           0\n",
       "spotify_listening_device       0\n",
       "spotify_subscription_plan      0\n",
       "premium_sub_willingness        0\n",
       "preferred_premium_plan         0\n",
       "preferred_listening_content    0\n",
       "fav_music_genre                0\n",
       "music_time_slot                0\n",
       "music_influential_mood         0\n",
       "music_lis_frequency            0\n",
       "music_expl_method              0\n",
       "music_rec_rating               0\n",
       "pod_lis_frequency              0\n",
       "fav_pod_genre                  0\n",
       "preferred_pod_format           0\n",
       "pod_host_preference            0\n",
       "preferred_pod_duration         0\n",
       "pod_variety_satisfaction       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I saved the cleaned data to a csv, which you can find [here](https://github.com/anly501/dsan-5000-project-pschenfeld/blob/main/data/clean_data/spotify_user_behavior/spotify_user_behavior.csv)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
